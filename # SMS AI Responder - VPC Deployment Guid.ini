# SMS AI Responder - VPC Deployment Guide

## Architecture Overview

Your 5-server VPC setup provides excellent separation of concerns:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                            VPC                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ   Web       ‚îÇ  ‚îÇ  Backend    ‚îÇ  ‚îÇ  Database   ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  (Frontend) ‚îÇ  ‚îÇ  (Flask)    ‚îÇ  ‚îÇ (PostgreSQL)‚îÇ              ‚îÇ
‚îÇ  ‚îÇ   :3000     ‚îÇ  ‚îÇ   :5000     ‚îÇ  ‚îÇ   :5432     ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ         ‚îÇ                 ‚îÇ                ‚îÇ                    ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ
‚îÇ                           ‚îÇ                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ
‚îÇ  ‚îÇ   Redis     ‚îÇ  ‚îÇ     LLM     ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ  (Cache)    ‚îÇ  ‚îÇ  (AI Model) ‚îÇ                              ‚îÇ
‚îÇ  ‚îÇ   :6379     ‚îÇ  ‚îÇ   :8080     ‚îÇ                              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 1. Database Server Configuration

### Prerequisites
```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install PostgreSQL 15
sudo apt install postgresql-15 postgresql-client-15 postgresql-contrib-15
```

### PostgreSQL Setup
```bash
# Switch to postgres user
sudo -u postgres psql

-- Create databases
CREATE DATABASE escort_sms_prod;
CREATE DATABASE escort_sms_dev;
CREATE DATABASE escort_sms_test;

-- Create application user with strong authentication
CREATE USER sms_app WITH PASSWORD 'your_secure_password' LOGIN;

-- Grant permissions with proper restrictions
GRANT CONNECT ON DATABASE escort_sms_prod TO sms_app;
GRANT CONNECT ON DATABASE escort_sms_dev TO sms_app;
GRANT CONNECT ON DATABASE escort_sms_test TO sms_app;

-- Connect to production database and grant schema permissions
\c escort_sms_prod
GRANT USAGE, CREATE ON SCHEMA public TO sms_app;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO sms_app;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO sms_app;

-- Set default privileges for future tables
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES TO sms_app;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON SEQUENCES TO sms_app;

-- Repeat for dev database
\c escort_sms_dev
GRANT USAGE, CREATE ON SCHEMA public TO sms_app;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO sms_app;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO sms_app;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES TO sms_app;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON SEQUENCES TO sms_app;

-- Exit psql
\q
```

### Configure PostgreSQL for Remote Access & Security
```bash
# Edit postgresql.conf
sudo nano /etc/postgresql/15/main/postgresql.conf

# Add/modify these lines for security and performance:
listen_addresses = '*'
port = 5432
max_connections = 200
shared_buffers = 256MB
effective_cache_size = 1GB
maintenance_work_mem = 64MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100

# Enable SSL/TLS encryption
ssl = on
ssl_cert_file = '/etc/ssl/certs/ssl-cert-snakeoil.pem'
ssl_key_file = '/etc/ssl/private/ssl-cert-snakeoil.key'
ssl_min_protocol_version = 'TLSv1.2'

# Security settings - 2025 Best Practices
password_encryption = scram-sha-256
log_connections = on
log_disconnections = on
log_statement = 'ddl'
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
logging_collector = on
log_directory = 'pg_log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_rotation_age = 1d
log_rotation_size = 10MB

# Row Level Security settings
row_security = on

# Connection security
tcp_keepalives_idle = 7200
tcp_keepalives_interval = 75
tcp_keepalives_count = 9
```

```bash
# Edit pg_hba.conf for VPC access with enhanced security
sudo nano /etc/postgresql/15/main/pg_hba.conf

# Replace the default configuration with:
# TYPE  DATABASE        USER            ADDRESS                 METHOD

# "local" is for Unix domain socket connections only
local   all             postgres                                peer
local   all             all                                     scram-sha-256

# IPv4 local connections:
host    all             postgres        127.0.0.1/32            scram-sha-256

# VPC connections with SSL required (replace with your VPC CIDR)
hostssl escort_sms_prod sms_app         10.0.0.0/16             scram-sha-256
hostssl escort_sms_dev  sms_app         10.0.0.0/16             scram-sha-256

# Deny all other connections
host    all             all             0.0.0.0/0               reject

# Restart PostgreSQL
sudo systemctl restart postgresql
sudo systemctl enable postgresql

# Test connection with SSL
psql "postgresql://sms_app@your-db-server-ip:5432/escort_sms_prod?sslmode=require" -c "SELECT version();"
```

### Database Backup & Security Script
```bash
# Create comprehensive backup script
sudo nano /opt/backup-db.sh

#!/bin/bash
set -e

BACKUP_DIR="/opt/backups"
DATE=$(date +"%Y%m%d_%H%M%S")
DB_NAME="escort_sms_prod"
DB_USER="sms_app"
DB_HOST="localhost"
RETENTION_DAYS=7

# Create backup directory
mkdir -p $BACKUP_DIR

# Create full database backup with compression
pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME -F c -v --no-owner --no-privileges > $BACKUP_DIR/backup_$DATE.dump

# Create schema-only backup for disaster recovery
pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME -s > $BACKUP_DIR/schema_$DATE.sql

# Verify backup integrity
pg_restore --list $BACKUP_DIR/backup_$DATE.dump > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "$(date): Backup successful - backup_$DATE.dump" >> $BACKUP_DIR/backup.log
else
    echo "$(date): Backup verification failed - backup_$DATE.dump" >> $BACKUP_DIR/backup.log
    exit 1
fi

# Encrypt backup for security (optional but recommended)
gpg --cipher-algo AES256 --compress-algo 1 --s2k-mode 3 \
    --s2k-digest-algo SHA512 --s2k-count 65536 --force-mdc \
    --symmetric --output $BACKUP_DIR/backup_$DATE.dump.gpg $BACKUP_DIR/backup_$DATE.dump

# Remove unencrypted backup if encryption succeeded
if [ -f $BACKUP_DIR/backup_$DATE.dump.gpg ]; then
    rm $BACKUP_DIR/backup_$DATE.dump
fi

# Clean old backups
find $BACKUP_DIR -name "backup_*.dump*" -mtime +$RETENTION_DAYS -delete
find $BACKUP_DIR -name "schema_*.sql" -mtime +$RETENTION_DAYS -delete

# Log cleanup
echo "$(date): Cleaned backups older than $RETENTION_DAYS days" >> $BACKUP_DIR/backup.log

# Make executable
chmod +x /opt/backup-db.sh

# Add to crontab for automated backups
echo "0 2 * * * /opt/backup-db.sh" | sudo crontab -

# Create backup monitoring script
sudo nano /opt/check-backup.sh

#!/bin/bash
BACKUP_DIR="/opt/backups"
LAST_BACKUP=$(find $BACKUP_DIR -name "backup_*.dump*" -mtime -1 | wc -l)

if [ $LAST_BACKUP -eq 0 ]; then
    echo "WARNING: No backup found in the last 24 hours"
    # Send alert (configure with your notification system)
else
    echo "OK: Recent backup found"
fi

chmod +x /opt/check-backup.sh
```

## 2. Redis Server Configuration

### Installation
```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install Redis
sudo apt install redis-server

# Configure Redis
sudo nano /etc/redis/redis.conf
```

### Redis Configuration
```conf
# /etc/redis/redis.conf

# Bind to all interfaces within VPC
bind 0.0.0.0

# Set password (uncomment and set)
requirepass your_redis_password

# Set max memory and eviction policy
maxmemory 1gb
maxmemory-policy allkeys-lru

# Enable persistence
save 900 1
save 300 10
save 60 10000

# Set log level
loglevel notice
logfile /var/log/redis/redis-server.log

# Security settings
protected-mode yes
tcp-keepalive 300
timeout 0
```

### Start and Enable Redis
```bash
sudo systemctl restart redis-server
sudo systemctl enable redis-server

# Test Redis
redis-cli -a your_redis_password ping
```

## 3. LLM Server Configuration

### Option A: Self-Hosted LLM (Ollama)
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Configure for network access
sudo nano /etc/systemd/system/ollama.service

[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="OLLAMA_HOST=0.0.0.0:8080"

[Install]
WantedBy=default.target

# Reload and start
sudo systemctl daemon-reload
sudo systemctl enable ollama
sudo systemctl start ollama

# Download a model (example: Code Llama)
ollama pull codellama:7b
```

### Option B: OpenAI API Proxy
```bash
# Install Node.js
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs

# Create proxy service
mkdir -p /opt/ai-proxy
cd /opt/ai-proxy

# Package.json
cat > package.json << EOF
{
  "name": "ai-proxy",
  "version": "1.0.0",
  "dependencies": {
    "express": "^4.18.2",
    "axios": "^1.6.0",
    "cors": "^2.8.5"
  }
}
EOF

npm install

# Proxy server
cat > server.js << 'EOF'
const express = require('express');
const axios = require('axios');
const cors = require('cors');

const app = express();
const PORT = 8080;

app.use(cors());
app.use(express.json());

app.post('/v1/chat/completions', async (req, res) => {
  try {
    const response = await axios.post('https://api.openai.com/v1/chat/completions', req.body, {
      headers: {
        'Authorization': req.headers.authorization,
        'Content-Type': 'application/json'
      }
    });
    res.json(response.data);
  } catch (error) {
    res.status(error.response?.status || 500).json(error.response?.data || {error: 'Internal server error'});
  }
});

app.listen(PORT, '0.0.0.0', () => {
  console.log(`AI Proxy running on port ${PORT}`);
});
EOF

# Create systemd service
sudo nano /etc/systemd/system/ai-proxy.service
```

```ini
[Unit]
Description=AI Proxy Service
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/opt/ai-proxy
ExecStart=/usr/bin/node server.js
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl enable ai-proxy
sudo systemctl start ai-proxy
```

## 4. Backend Server Configuration

### Environment Setup
```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install Python and dependencies
sudo apt install python3.11 python3.11-venv python3-pip nginx supervisor

# Create application user
sudo useradd -m -s /bin/bash smsapp
sudo mkdir -p /opt/sms-backend
sudo chown smsapp:smsapp /opt/sms-backend
```

### Application Deployment
```bash
# Switch to app user
sudo -u smsapp -i

# Navigate to app directory
cd /opt/sms-backend

# Clone or upload your code
git clone <your-repository> .
# OR
# Upload your code via SCP/SFTP

# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create production environment file
nano .env.production
```

### Production Environment Variables
```env
# .env.production
FLASK_ENV=production
SECRET_KEY=your-super-secret-production-key-at-least-32-chars
JWT_SECRET_KEY=your-jwt-secret-production-key-at-least-32-chars

# Generate secure keys with:
# python -c 'import secrets; print(secrets.token_hex(32))'

# Database with SSL (replace IP with your DB server IP)
DATABASE_URL=postgresql://sms_app:your_secure_password@10.0.1.100:5432/escort_sms_prod?sslmode=require

# Redis with password (replace IP with your Redis server IP)
CELERY_BROKER_URL=redis://:your_redis_password@10.0.1.101:6379/0
CELERY_RESULT_BACKEND=redis://:your_redis_password@10.0.1.101:6379/0

# Twilio
TWILIO_ACCOUNT_SID=your_twilio_sid
TWILIO_AUTH_TOKEN=your_twilio_token
VERIFY_TWILIO_SIGNATURE=True

# AI Service (replace IP with your LLM server IP)
OPENAI_API_KEY=your_openai_key
OPENAI_API_BASE=http://10.0.1.102:8080/v1  # For self-hosted
# OPENAI_API_BASE=https://api.openai.com/v1  # For OpenAI API

# Stripe
STRIPE_SECRET_KEY=your_stripe_secret
STRIPE_WEBHOOK_SECRET=your_stripe_webhook_secret

# Security Headers
SESSION_COOKIE_SECURE=True
SESSION_COOKIE_HTTPONLY=True
SESSION_COOKIE_SAMESITE=Lax
PERMANENT_SESSION_LIFETIME=3600

# Rate Limiting
RATELIMIT_STORAGE_URL=redis://:your_redis_password@10.0.1.101:6379/1
```

### Database Migration
```bash
# Activate virtual environment
source venv/bin/activate

# Set environment
export FLASK_APP=wsgi.py
export FLASK_ENV=production

# Run migrations
flask db upgrade

# Create admin user (optional)
python scripts/create_admin.py
```

### Gunicorn Configuration
```bash
# Create gunicorn config
nano /opt/sms-backend/gunicorn.conf.py
```

```python
# gunicorn.conf.py
bind = "127.0.0.1:5000"
workers = 4
worker_class = "eventlet"
worker_connections = 1000
timeout = 120
keepalive = 5
max_requests = 1000
max_requests_jitter = 100
user = "smsapp"
group = "smsapp"
```

### Supervisor Configuration
```bash
# Configure supervisor for Flask app
sudo nano /etc/supervisor/conf.d/sms-backend.conf
```

```ini
[program:sms-backend]
command=/opt/sms-backend/venv/bin/gunicorn -c gunicorn.conf.py wsgi:app
directory=/opt/sms-backend
user=smsapp
autostart=true
autorestart=true
stderr_logfile=/var/log/sms-backend.err.log
stdout_logfile=/var/log/sms-backend.out.log
environment=FLASK_ENV="production"

[program:sms-celery]
command=/opt/sms-backend/venv/bin/celery -A app.celery worker --loglevel=info
directory=/opt/sms-backend
user=smsapp
autostart=true
autorestart=true
stderr_logfile=/var/log/sms-celery.err.log
stdout_logfile=/var/log/sms-celery.out.log
environment=FLASK_ENV="production"
```

```bash
# Update supervisor
sudo supervisorctl reread
sudo supervisorctl update
sudo supervisorctl start all
```

### Nginx Configuration
```bash
# Configure Nginx
sudo nano /etc/nginx/sites-available/sms-backend
```

```nginx
server {
    listen 80;
    server_name your-backend-domain.com;

    location / {
        proxy_pass http://127.0.0.1:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_buffering off;
    }

    location /socket.io/ {
        proxy_pass http://127.0.0.1:5000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

```bash
# Enable site
sudo ln -s /etc/nginx/sites-available/sms-backend /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx
```

## 5. Web Server Configuration (Frontend)

### Environment Setup
```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install Node.js
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs nginx

# Install PM2 for process management
sudo npm install -g pm2
```

### Application Deployment
```bash
# Create application directory
sudo mkdir -p /opt/sms-frontend
sudo chown $USER:$USER /opt/sms-frontend

# Navigate to directory
cd /opt/sms-frontend

# Clone your frontend code
git clone <your-frontend-repository> .

# Install dependencies
npm install

# Create production environment file
nano .env.production
```

### Frontend Environment Variables
```env
# .env.production
REACT_APP_API_URL=http://your-backend-server-ip:5000
REACT_APP_WS_URL=ws://your-backend-server-ip:5000
REACT_APP_STRIPE_PUBLIC_KEY=your_stripe_public_key
```

### Build and Deploy
```bash
# Build production version
npm run build

# Configure PM2
cat > ecosystem.config.js << 'EOF'
module.exports = {
  apps: [{
    name: 'sms-frontend',
    script: 'npx',
    args: 'serve -s build -p 3000',
    instances: 2,
    exec_mode: 'cluster',
    env: {
      NODE_ENV: 'production'
    }
  }]
};
EOF

# Start with PM2
pm2 start ecosystem.config.js
pm2 save
pm2 startup
```

### Nginx Configuration for Frontend
```bash
sudo nano /etc/nginx/sites-available/sms-frontend
```

```nginx
server {
    listen 80;
    server_name your-frontend-domain.com;
    root /opt/sms-frontend/build;
    index index.html index.htm;

    location / {
        try_files $uri $uri/ /index.html;
    }

    location /static/ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css text/xml text/javascript application/javascript application/xml+rss application/json;
}
```

```bash
# Enable site
sudo ln -s /etc/nginx/sites-available/sms-frontend /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx
```

## 6. Security Group Configuration

### Database Server (Port 5432)
```
Inbound Rules:
- PostgreSQL: Port 5432, Source: Backend Server IP
- SSH: Port 22, Source: Your Management IP

Outbound Rules:
- All traffic: Allow (for updates)
```

### Redis Server (Port 6379)
```
Inbound Rules:
- Redis: Port 6379, Source: Backend Server IP
- SSH: Port 22, Source: Your Management IP

Outbound Rules:
- All traffic: Allow
```

### LLM Server (Port 8080)
```
Inbound Rules:
- HTTP: Port 8080, Source: Backend Server IP
- SSH: Port 22, Source: Your Management IP

Outbound Rules:
- All traffic: Allow
```

### Backend Server (Port 5000)
```
Inbound Rules:
- HTTP: Port 5000, Source: Web Server IP
- HTTPS: Port 443, Source: 0.0.0.0/0 (for Twilio webhooks)
- SSH: Port 22, Source: Your Management IP

Outbound Rules:
- All traffic: Allow
```

### Web Server (Port 3000)
```
Inbound Rules:
- HTTP: Port 80, Source: 0.0.0.0/0
- HTTPS: Port 443, Source: 0.0.0.0/0
- SSH: Port 22, Source: Your Management IP

Outbound Rules:
- All traffic: Allow
```

## 7. SSL/TLS Configuration

### Install Certbot
```bash
# On both web and backend servers
sudo apt install certbot python3-certbot-nginx

# Get SSL certificates
sudo certbot --nginx -d your-frontend-domain.com
sudo certbot --nginx -d your-backend-domain.com

# Auto-renewal
sudo systemctl enable certbot.timer
```

## 8. Security Hardening & Monitoring

### Install Security Tools
```bash
# On all servers
sudo apt install fail2ban ufw htop iotop nethogs unattended-upgrades

# Configure automatic security updates
sudo dpkg-reconfigure -plow unattended-upgrades
```

### Fail2Ban Configuration
```bash
# Configure Fail2Ban for SSH protection
sudo nano /etc/fail2ban/jail.local

[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 3
ignoreip = 127.0.0.1/8 10.0.0.0/16

[sshd]
enabled = true
port = ssh
filter = sshd
logpath = /var/log/auth.log
maxretry = 3

[nginx-http-auth]
enabled = true
filter = nginx-http-auth
port = http,https
logpath = /var/log/nginx/error.log

sudo systemctl enable fail2ban
sudo systemctl start fail2ban
```

### Firewall Configuration (UFW)
```bash
# Database Server
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow from 10.0.1.104 to any port 5432  # Backend server
sudo ufw allow ssh
sudo ufw enable

# Redis Server  
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow from 10.0.1.104 to any port 6379  # Backend server
sudo ufw allow ssh
sudo ufw enable

# Backend Server
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow from 10.0.1.105 to any port 5000   # Web server
sudo ufw allow 443                                 # Twilio webhooks
sudo ufw allow ssh
sudo ufw enable

# Web Server
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow 80
sudo ufw allow 443
sudo ufw allow ssh
sudo ufw enable

# LLM Server
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow from 10.0.1.104 to any port 8080   # Backend server
sudo ufw allow ssh
sudo ufw enable
```

### System Monitoring Setup
```bash
# Install monitoring tools
sudo apt install prometheus-node-exporter

# Create system monitoring script
sudo nano /opt/system-monitor.sh
```

```bash
#!/bin/bash
# Enhanced system monitoring script

LOG_FILE="/var/log/system-monitor.log"
DATE=$(date '+%Y-%m-%d %H:%M:%S')
ALERT_THRESHOLD_CPU=80
ALERT_THRESHOLD_MEM=85
ALERT_THRESHOLD_DISK=90

echo "[$DATE] System Status Check" >> $LOG_FILE

# Check CPU usage
CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')
if (( $(echo "$CPU_USAGE > $ALERT_THRESHOLD_CPU" | bc -l) )); then
    echo "[$DATE] ALERT: High CPU usage: $CPU_USAGE%" >> $LOG_FILE
fi

# Check memory usage
MEM_USAGE=$(free | grep Mem | awk '{printf("%.1f"), $3/$2 * 100.0}')
if (( $(echo "$MEM_USAGE > $ALERT_THRESHOLD_MEM" | bc -l) )); then
    echo "[$DATE] ALERT: High memory usage: $MEM_USAGE%" >> $LOG_FILE
fi

# Check disk usage
DISK_USAGE=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
if [ $DISK_USAGE -gt $ALERT_THRESHOLD_DISK ]; then
    echo "[$DATE] ALERT: High disk usage: $DISK_USAGE%" >> $LOG_FILE
fi

# Check running services based on server type
HOSTNAME=$(hostname)
case $HOSTNAME in
    *db*)
        systemctl is-active postgresql >> $LOG_FILE 2>&1
        ;;
    *redis*)
        systemctl is-active redis-server >> $LOG_FILE 2>&1
        ;;
    *backend*)
        systemctl is-active nginx >> $LOG_FILE 2>&1
        supervisorctl status >> $LOG_FILE 2>&1
        ;;
    *web*)
        systemctl is-active nginx >> $LOG_FILE 2>&1
        pm2 status >> $LOG_FILE 2>&1
        ;;
    *llm*)
        systemctl is-active ollama >> $LOG_FILE 2>&1  # or ai-proxy
        ;;
esac

# Check network connectivity between services
case $HOSTNAME in
    *backend*)
        # Test database connection
        pg_isready -h 10.0.1.100 -p 5432 -U sms_app >> $LOG_FILE 2>&1
        # Test Redis connection
        redis-cli -h 10.0.1.101 -p 6379 -a your_redis_password ping >> $LOG_FILE 2>&1
        # Test LLM service
        curl -s -o /dev/null -w "%{http_code}" http://10.0.1.102:8080/health >> $LOG_FILE 2>&1
        ;;
esac

echo "[$DATE] ------------------------" >> $LOG_FILE

# Make executable and add to cron
chmod +x /opt/system-monitor.sh
echo "*/5 * * * * /opt/system-monitor.sh" | sudo crontab -
```

### Log Rotation Configuration
```bash
# Configure log rotation for application logs
sudo nano /etc/logrotate.d/sms-app

/var/log/sms-*.log {
    daily
    missingok
    rotate 14
    compress
    delaycompress
    notifempty
    create 644 smsapp smsapp
    postrotate
        supervisorctl restart sms-backend
        supervisorctl restart sms-celery
    endscript
}

/opt/backups/backup.log {
    weekly
    missingok
    rotate 8
    compress
    delaycompress
    notifempty
}
```

## 9. Deployment Script

Create an automated deployment script:

```bash
#!/bin/bash
# deploy.sh - Automated deployment script

set -e

# Configuration
BACKEND_SERVER="10.0.1.104"
FRONTEND_SERVER="10.0.1.105"
DB_SERVER="10.0.1.100"
REDIS_SERVER="10.0.1.101"
LLM_SERVER="10.0.1.102"

echo "Starting deployment process..."

# Deploy backend
echo "Deploying backend..."
ssh smsapp@$BACKEND_SERVER << 'EOF'
cd /opt/sms-backend
git pull origin main
source venv/bin/activate
pip install -r requirements.txt
flask db upgrade
sudo supervisorctl restart sms-backend
sudo supervisorctl restart sms-celery
EOF

# Deploy frontend
echo "Deploying frontend..."
ssh ubuntu@$FRONTEND_SERVER << 'EOF'
cd /opt/sms-frontend
git pull origin main
npm install
npm run build
pm2 restart sms-frontend
EOF

echo "Deployment complete!"

# Health checks
echo "Running health checks..."
curl -f http://$BACKEND_SERVER:5000/api/health || echo "Backend health check failed"
curl -f http://$FRONTEND_SERVER:3000 || echo "Frontend health check failed"

echo "All done!"
```

## 10. Backup Strategy

### Database Backups
Already configured in Database Server section.

### Application Backups
```bash
# Create backup script for application files
sudo nano /opt/backup-app.sh
```

```bash
#!/bin/bash
BACKUP_DIR="/opt/backups"
DATE=$(date +"%Y%m%d_%H%M%S")

mkdir -p $BACKUP_DIR

# Backup backend
tar -czf $BACKUP_DIR/backend_$DATE.tar.gz -C /opt sms-backend

# Backup frontend
tar -czf $BACKUP_DIR/frontend_$DATE.tar.gz -C /opt sms-frontend

# Clean old backups (keep 14 days)
find $BACKUP_DIR -name "*.tar.gz" -mtime +14 -delete
```

## 11. Health Checks & Validation

### Create Health Check Endpoints
Add to your Flask application:

```python
# app/api/health.py
from flask import Blueprint, jsonify
from app.extensions import db
import redis
import requests

health_bp = Blueprint('health', __name__)

@health_bp.route('/health', methods=['GET'])
def health_check():
    """Comprehensive health check endpoint"""
    checks = {
        'status': 'healthy',
        'timestamp': datetime.utcnow().isoformat(),
        'checks': {}
    }
    
    # Database check
    try:
        db.engine.execute('SELECT 1')
        checks['checks']['database'] = 'healthy'
    except Exception as e:
        checks['checks']['database'] = f'unhealthy: {str(e)}'
        checks['status'] = 'unhealthy'
    
    # Redis check
    try:
        r = redis.Redis.from_url(current_app.config['CELERY_BROKER_URL'])
        r.ping()
        checks['checks']['redis'] = 'healthy'
    except Exception as e:
        checks['checks']['redis'] = f'unhealthy: {str(e)}'
        checks['status'] = 'unhealthy'
    
    # AI service check
    try:
        ai_url = current_app.config.get('OPENAI_API_BASE', 'https://api.openai.com/v1')
        if 'openai.com' not in ai_url:  # Self-hosted
            response = requests.get(f"{ai_url.replace('/v1', '')}/health", timeout=5)
            if response.status_code == 200:
                checks['checks']['ai_service'] = 'healthy'
            else:
                checks['checks']['ai_service'] = f'unhealthy: HTTP {response.status_code}'
                checks['status'] = 'unhealthy'
        else:
            checks['checks']['ai_service'] = 'external_service'
    except Exception as e:
        checks['checks']['ai_service'] = f'unhealthy: {str(e)}'
        checks['status'] = 'unhealthy'
    
    status_code = 200 if checks['status'] == 'healthy' else 503
    return jsonify(checks), status_code

@health_bp.route('/ready', methods=['GET'])
def readiness_check():
    """Kubernetes/Docker readiness probe"""
    return jsonify({'status': 'ready'}), 200

@health_bp.route('/live', methods=['GET'])
def liveness_check():
    """Kubernetes/Docker liveness probe"""
    return jsonify({'status': 'alive'}), 200
```

### Deployment Validation Script
```bash
#!/bin/bash
# validate-deployment.sh - Comprehensive deployment validation

set -e

echo "üöÄ Starting deployment validation..."

# Configuration
BACKEND_URL="http://10.0.1.104:5000"
FRONTEND_URL="http://10.0.1.105:3000"
DB_HOST="10.0.1.100"
REDIS_HOST="10.0.1.101"
LLM_HOST="10.0.1.102"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Function to print status
print_status() {
    if [ $1 -eq 0 ]; then
        echo -e "${GREEN}‚úÖ $2${NC}"
    else
        echo -e "${RED}‚ùå $2${NC}"
        exit 1
    fi
}

# Function to print warning
print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

echo "üìã Validating infrastructure..."

# Test database connectivity
echo "üîç Testing database connection..."
pg_isready -h $DB_HOST -p 5432 -U sms_app -d escort_sms_prod
print_status $? "Database connectivity"

# Test Redis connectivity
echo "üîç Testing Redis connection..."
redis-cli -h $REDIS_HOST -p 6379 -a your_redis_password ping > /dev/null 2>&1
print_status $? "Redis connectivity"

# Test LLM service
echo "üîç Testing LLM service..."
if curl -f -s http://$LLM_HOST:8080/health > /dev/null 2>&1; then
    print_status 0 "LLM service health"
else
    print_warning "LLM service health check failed or not available"
fi

# Test backend health
echo "üîç Testing backend health..."
HEALTH_RESPONSE=$(curl -s -w "%{http_code}" $BACKEND_URL/api/health)
HTTP_CODE=${HEALTH_RESPONSE: -3}
if [ "$HTTP_CODE" = "200" ]; then
    print_status 0 "Backend health check"
else
    print_status 1 "Backend health check (HTTP $HTTP_CODE)"
fi

# Test backend API endpoints
echo "üîç Testing backend API endpoints..."
curl -f -s $BACKEND_URL/api/auth/health > /dev/null 2>&1
print_status $? "Authentication endpoints"

# Test frontend
echo "üîç Testing frontend..."
curl -f -s $FRONTEND_URL > /dev/null 2>&1
print_status $? "Frontend accessibility"

# Test SSL certificates (if configured)
echo "üîç Testing SSL certificates..."
if command -v openssl &> /dev/null; then
    if openssl s_client -connect your-domain.com:443 -servername your-domain.com < /dev/null 2>/dev/null | grep -q "Verify return code: 0"; then
        print_status 0 "SSL certificate validation"
    else
        print_warning "SSL certificate validation failed or not configured"
    fi
else
    print_warning "OpenSSL not available for certificate testing"
fi

# Test Twilio webhook accessibility
echo "üîç Testing Twilio webhook accessibility..."
if curl -f -s -X POST $BACKEND_URL/api/webhooks/sms -d "test=1" > /dev/null 2>&1; then
    print_status 0 "Twilio webhook endpoint"
else
    print_warning "Twilio webhook endpoint test failed (expected for production)"
fi

# Performance tests
echo "üîç Running basic performance tests..."
RESPONSE_TIME=$(curl -o /dev/null -s -w "%{time_total}" $BACKEND_URL/api/health)
if (( $(echo "$RESPONSE_TIME < 2.0" | bc -l) )); then
    print_status 0 "Backend response time ($RESPONSE_TIME seconds)"
else
    print_warning "Backend response time is slow ($RESPONSE_TIME seconds)"
fi

# Check disk space on all servers
echo "üîç Checking disk space..."
SERVERS=("10.0.1.100" "10.0.1.101" "10.0.1.102" "10.0.1.104" "10.0.1.105")
for server in "${SERVERS[@]}"; do
    if ssh -o ConnectTimeout=5 ubuntu@$server "df -h / | awk 'NR==2 {if(\$5+0 < 90) print \"OK\"; else print \"WARN\";}'" 2>/dev/null | grep -q "OK"; then
        print_status 0 "Disk space on $server"
    else
        print_warning "High disk usage or connection failed on $server"
    fi
done

# Check log files for recent errors
echo "üîç Checking for recent errors..."
if journalctl --since "1 hour ago" --priority=err --quiet --no-pager | grep -q .; then
    print_warning "Recent errors found in system logs"
else
    print_status 0 "No recent critical errors in logs"
fi

echo ""
echo "üéâ Deployment validation completed successfully!"
echo ""
echo "üìä Next steps:"
echo "1. Monitor application logs for the next 30 minutes"
echo "2. Test user registration and profile creation"
echo "3. Send test SMS messages"
echo "4. Verify AI responses are generated correctly"
echo "5. Check that webhooks are receiving messages from Twilio"
echo ""
echo "üìù Monitoring commands:"
echo "- Backend logs: sudo supervisorctl tail -f sms-backend"
echo "- Celery logs: sudo supervisorctl tail -f sms-celery"
echo "- Nginx logs: sudo tail -f /var/log/nginx/access.log"
echo "- System logs: sudo journalctl -f"

# Make executable
chmod +x validate-deployment.sh
```

### Automated Testing Script
```bash
#!/bin/bash
# smoke-tests.sh - Post-deployment smoke tests

echo "üß™ Running smoke tests..."

API_BASE="http://10.0.1.104:5000/api"

# Test user registration
echo "Testing user registration..."
REGISTER_RESPONSE=$(curl -s -X POST $API_BASE/auth/register \
  -H "Content-Type: application/json" \
  -d '{"username":"testuser","email":"test@example.com","password":"testpass123"}' \
  -w "%{http_code}")

if echo "$REGISTER_RESPONSE" | grep -q "201"; then
    echo "‚úÖ User registration test passed"
else
    echo "‚ùå User registration test failed"
fi

# Test profile creation (requires authentication)
echo "Testing profile creation..."
# Extract token from registration response
TOKEN=$(echo "$REGISTER_RESPONSE" | jq -r '.access_token' 2>/dev/null)

if [ "$TOKEN" != "null" ] && [ -n "$TOKEN" ]; then
    PROFILE_RESPONSE=$(curl -s -X POST $API_BASE/profiles \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $TOKEN" \
      -d '{"name":"Test Profile","phone_number":"+1234567890"}' \
      -w "%{http_code}")
    
    if echo "$PROFILE_RESPONSE" | grep -q "201"; then
        echo "‚úÖ Profile creation test passed"
    else
        echo "‚ùå Profile creation test failed"
    fi
else
    echo "‚ö†Ô∏è  Skipping profile test - no auth token"
fi

echo "üß™ Smoke tests completed"

chmod +x smoke-tests.sh
```

This comprehensive deployment guide provides enterprise-grade security, monitoring, and validation for your SMS AI Responder platform. The architecture is designed for scalability, security, and maintainability based on 2025 best practices.